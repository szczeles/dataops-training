{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "    .config('spark.sql.sources.partitionOverwriteMode', 'dynamic')\n",
    "    .config('hive.exec.dynamic.partition.mode', 'nonstrict')\n",
    "    .enableHiveSupport().getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! hdfs dfs -ls /data/stackoverflow/parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.catalog.createTable('stackoverflow.tags', path='/data/stackoverflow/parquet/Tags')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY = '2019-09-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = spark.table('stackoverflow.posts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# posts.groupBy('PostTypeId').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_question = (col('PostTypeId') == 1) # according to https://ia800107.us.archive.org/27/items/stackexchange/readme.txt\n",
    "tag_popularity_in_questions = posts.where(is_question & (col('CreationDate').cast('date') == DAY)) \\\n",
    "    .select('Id', explode('Tags').alias('tag')) \\\n",
    "    .groupBy('tag').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag_popularity_in_questions.orderBy(desc('count')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_answer = (col('PostTypeId') == 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_today = posts.where(is_answer & (col('CreationDate').cast('date') == DAY)).alias('a')\n",
    "all_questions = posts.where(is_question).alias('q')\n",
    "tag_popularity_in_answers = answers_today.join(all_questions, col('a.ParentId') == col('q.Id')).select('q.Tags') \\\n",
    "    .select(explode('Tags').alias('tag')).groupBy('tag').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "votes = spark.table('stackoverflow.votes')\n",
    "votes_today = votes.where(col('VoteTypeId').isin(2, 3)) \\\n",
    "    .where(col('CreationDate').cast('date') == DAY).select('PostId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.conf.set('spark.sql.autoBroadcastJoinThreshold', '1000000')\n",
    "# https://jaceklaskowski.gitbooks.io/mastering-spark-sql/spark-sql-joins-broadcast.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_questions = posts.where(is_question).drop('PostTypeId').alias('q')\n",
    "all_posts = posts.alias('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_popularity_in_votes = all_posts.join(broadcast(votes_today), votes_today.PostId == col('p.Id')) \\\n",
    "    .join(all_questions, col('q.Id') == col('p.ParentId'), how='left') \\\n",
    "    .select(coalesce('q.Tags', 'p.Tags').alias('valid_tags')) \\\n",
    "    .select(explode('valid_tags').alias('tag')).groupBy('tag').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_points = tag_popularity_in_questions.withColumnRenamed('count', 'questions')\n",
    "answers_points = tag_popularity_in_answers.withColumnRenamed('count', 'answers')\n",
    "votes_points = tag_popularity_in_votes.withColumnRenamed('count', 'votes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(21) Project [coalesce(tag#453, tag#437) AS tag#457, coalesce(questions#444L, 0) AS questions#466L, coalesce(answers#447L, 0) AS answers#467L, coalesce(votes#450L, 0) AS votes#468L, 2019-09-01 AS dt#473]\n",
      "+- SortMergeJoin [tag#453], [tag#437], FullOuter\n",
      "   :- *(12) Sort [tag#453 ASC NULLS FIRST], false, 0\n",
      "   :  +- Exchange hashpartitioning(tag#453, 200)\n",
      "   :     +- *(11) Project [coalesce(tag#41, tag#192) AS tag#453, questions#444L, answers#447L]\n",
      "   :        +- SortMergeJoin [tag#41], [tag#192], FullOuter\n",
      "   :           :- *(3) Sort [tag#41 ASC NULLS FIRST], false, 0\n",
      "   :           :  +- *(3) HashAggregate(keys=[tag#41], functions=[count(1)])\n",
      "   :           :     +- Exchange hashpartitioning(tag#41, 200)\n",
      "   :           :        +- *(2) HashAggregate(keys=[tag#41], functions=[partial_count(1)])\n",
      "   :           :           +- Generate explode(Tags#9), false, [tag#41]\n",
      "   :           :              +- *(1) Project [Tags#9]\n",
      "   :           :                 +- *(1) Filter (((isnotnull(PostTypeId#2) && isnotnull(CreationDate#3)) && (PostTypeId#2 = 1)) && (cast(cast(CreationDate#3 as date) as string) = 2019-09-01))\n",
      "   :           :                    +- *(1) FileScan parquet stackoverflow.posts[PostTypeId#2,CreationDate#3,Tags#9] Batched: false, Format: Parquet, Location: InMemoryFileIndex[hdfs://namenode:9000/data/stackoverflow/parquet/Posts], PartitionFilters: [], PushedFilters: [IsNotNull(PostTypeId), IsNotNull(CreationDate), EqualTo(PostTypeId,1)], ReadSchema: struct<PostTypeId:int,CreationDate:timestamp,Tags:array<string>>\n",
      "   :           +- *(10) Sort [tag#192 ASC NULLS FIRST], false, 0\n",
      "   :              +- *(10) HashAggregate(keys=[tag#192], functions=[count(1)])\n",
      "   :                 +- Exchange hashpartitioning(tag#192, 200)\n",
      "   :                    +- *(9) HashAggregate(keys=[tag#192], functions=[partial_count(1)])\n",
      "   :                       +- Generate explode(Tags#59), false, [tag#192]\n",
      "   :                          +- *(8) Project [Tags#59]\n",
      "   :                             +- *(8) SortMergeJoin [ParentId#1], [Id#50], Inner\n",
      "   :                                :- *(5) Sort [ParentId#1 ASC NULLS FIRST], false, 0\n",
      "   :                                :  +- Exchange hashpartitioning(ParentId#1, 200)\n",
      "   :                                :     +- *(4) Project [ParentId#1]\n",
      "   :                                :        +- *(4) Filter ((((isnotnull(PostTypeId#2) && isnotnull(CreationDate#3)) && (PostTypeId#2 = 2)) && (cast(cast(CreationDate#3 as date) as string) = 2019-09-01)) && isnotnull(ParentId#1))\n",
      "   :                                :           +- *(4) FileScan parquet stackoverflow.posts[ParentId#1,PostTypeId#2,CreationDate#3] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://namenode:9000/data/stackoverflow/parquet/Posts], PartitionFilters: [], PushedFilters: [IsNotNull(PostTypeId), IsNotNull(CreationDate), EqualTo(PostTypeId,2), IsNotNull(ParentId)], ReadSchema: struct<ParentId:int,PostTypeId:int,CreationDate:timestamp>\n",
      "   :                                +- *(7) Sort [Id#50 ASC NULLS FIRST], false, 0\n",
      "   :                                   +- Exchange hashpartitioning(Id#50, 200)\n",
      "   :                                      +- *(6) Project [Id#50, Tags#59]\n",
      "   :                                         +- *(6) Filter ((isnotnull(PostTypeId#52) && (PostTypeId#52 = 1)) && isnotnull(Id#50))\n",
      "   :                                            +- *(6) FileScan parquet stackoverflow.posts[Id#50,PostTypeId#52,Tags#59] Batched: false, Format: Parquet, Location: InMemoryFileIndex[hdfs://namenode:9000/data/stackoverflow/parquet/Posts], PartitionFilters: [], PushedFilters: [IsNotNull(PostTypeId), EqualTo(PostTypeId,1), IsNotNull(Id)], ReadSchema: struct<Id:int,PostTypeId:int,Tags:array<string>>\n",
      "   +- *(20) Sort [tag#437 ASC NULLS FIRST], false, 0\n",
      "      +- *(20) HashAggregate(keys=[tag#437], functions=[count(1)])\n",
      "         +- Exchange hashpartitioning(tag#437, 200)\n",
      "            +- *(19) HashAggregate(keys=[tag#437], functions=[partial_count(1)])\n",
      "               +- Generate explode(valid_tags#434), false, [tag#437]\n",
      "                  +- *(18) Project [coalesce(Tags#303, Tags#9) AS valid_tags#434]\n",
      "                     +- SortMergeJoin [ParentId#1], [Id#294], LeftOuter\n",
      "                        :- *(15) Sort [ParentId#1 ASC NULLS FIRST], false, 0\n",
      "                        :  +- Exchange hashpartitioning(ParentId#1, 200)\n",
      "                        :     +- *(14) Project [ParentId#1, Tags#9]\n",
      "                        :        +- *(14) BroadcastHashJoin [Id#0], [PostId#200], Inner, BuildRight\n",
      "                        :           :- *(14) Project [Id#0, ParentId#1, Tags#9]\n",
      "                        :           :  +- *(14) Filter isnotnull(Id#0)\n",
      "                        :           :     +- *(14) FileScan parquet stackoverflow.posts[Id#0,ParentId#1,Tags#9] Batched: false, Format: Parquet, Location: InMemoryFileIndex[hdfs://namenode:9000/data/stackoverflow/parquet/Posts], PartitionFilters: [], PushedFilters: [IsNotNull(Id)], ReadSchema: struct<Id:int,ParentId:int,Tags:array<string>>\n",
      "                        :           +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)))\n",
      "                        :              +- *(13) Project [PostId#200]\n",
      "                        :                 +- *(13) Filter (((isnotnull(CreationDate#203) && VoteTypeId#201 IN (2,3)) && (cast(cast(CreationDate#203 as date) as string) = 2019-09-01)) && isnotnull(PostId#200))\n",
      "                        :                    +- *(13) FileScan parquet stackoverflow.votes[PostId#200,VoteTypeId#201,CreationDate#203] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://namenode:9000/data/stackoverflow/parquet/Votes], PartitionFilters: [], PushedFilters: [IsNotNull(CreationDate), In(VoteTypeId, [2,3]), IsNotNull(PostId)], ReadSchema: struct<PostId:int,VoteTypeId:int,CreationDate:timestamp>\n",
      "                        +- *(17) Sort [Id#294 ASC NULLS FIRST], false, 0\n",
      "                           +- ReusedExchange [Id#294, Tags#303], Exchange hashpartitioning(Id#50, 200)\n"
     ]
    }
   ],
   "source": [
    "questions_points.join(answers_points, 'tag', how='full') \\\n",
    "    .join(votes_points, 'tag', how='full').fillna(0, ['questions', 'answers', 'votes']) \\\n",
    "    .withColumn('dt', lit(DAY)).explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
